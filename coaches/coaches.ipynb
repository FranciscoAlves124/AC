{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1c516b",
   "metadata": {},
   "source": [
    "# Basketball Season: Predicting Coach Changes\n",
    "\n",
    "**Project Context**\n",
    "This notebook addresses **Task (b)** of the project description: \"Set of teams that will change coaches\". The goal is to utilize 10 years of historical data regarding players, teams, and games to predict which teams will replace their head coach during the test season (Year 11).\n",
    "\n",
    "**Data Sources**\n",
    "The analysis utilizes the following relational tables provided in the dataset:\n",
    "* **`coaches`**: History of coaches, including stints and win/loss records.\n",
    "* **`teams`**: Seasonal performance metrics for every team.\n",
    "* **`players_teams`**: Performance metrics for players within specific teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. Define File Paths\n",
    "# Assuming standard directory structure as per the problem description\n",
    "initial_path = '../data/initial_data/'\n",
    "test_path = '../data/test_data/'\n",
    "\n",
    "def load_and_combine(filename):\n",
    "    # Load historical data\n",
    "    df = pd.read_csv(f\"{initial_path}{filename}\")\n",
    "    \n",
    "    # Try to load test data if it exists (it might not exist for all files)\n",
    "    try:\n",
    "        df_test = pd.read_csv(f\"{test_path}{filename}\")\n",
    "        # Concatenate: this ensures Year 11 is at the end of the dataframe\n",
    "        df = pd.concat([df, df_test], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "# Load all relevant tables\n",
    "coaches = load_and_combine('coaches.csv')\n",
    "teams = load_and_combine('teams.csv')\n",
    "players_teams = load_and_combine('players_teams.csv')\n",
    "\n",
    "# Ensure data is sorted chronologically\n",
    "teams = teams.sort_values(['year', 'tmID'])\n",
    "coaches = coaches.sort_values(['year', 'tmID'])\n",
    "\n",
    "display(coaches.head())\n",
    "display(teams.head())\n",
    "display(players_teams.head())\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f98b8b",
   "metadata": {},
   "source": [
    "### 2. Defining the Target Variable\n",
    "The objective is to identify mid-season coach changes. In the `coaches` dataset, a `stint` greater than 0 indicates that a coach took over after the season began or that multiple coaches managed the team in a single year.\n",
    "\n",
    "* **Target (`CoachChange`)**: Boolean flag indicating if a team had a `stint > 0` in a given year.\n",
    "* **Scope**: We define this for the training years (1-10) and aim to predict it for the test year (11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = coaches.groupby(['year', 'tmID'])['stint'].max().reset_index()\n",
    "target_df['CoachChange'] = target_df['stint'] > 0\n",
    "\n",
    "target_df = target_df[['year', 'tmID', 'CoachChange']]\n",
    "\n",
    "print(\"\\n--- Target Variable 'CoachChange' Created ---\")\n",
    "print(target_df[target_df['CoachChange'] == True])\n",
    "print(f\"\\nTotal 'CoachChange = True' events: {int(target_df['CoachChange'].sum())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dbed7",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering: Coach Tenure & Stability\n",
    "Hypothesis: A coach who has just started (low tenure) or has survived many years (high tenure) has a different risk profile than one in the middle of a contract.\n",
    "\n",
    "We calculate:\n",
    "* **`coach_tenure_years`**: The cumulative number of years a specific `coachID` has managed a specific `tmID` without interruption.\n",
    "* **`coach_spell`**: A unique identifier for a specific contiguous period a coach spends with a team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to main coaches (stint == 0)\n",
    "main_coaches = coaches[(coaches['stint'] == 0) | (coaches['stint'] == 1)].copy()\n",
    "\n",
    "# Sort by team and year to ensure order\n",
    "main_coaches = main_coaches.sort_values(['tmID', 'year'])\n",
    "\n",
    "# Logic: Check if the coachID changed from the previous year\n",
    "main_coaches['prev_coach'] = main_coaches.groupby('tmID')['coachID'].shift(1)\n",
    "main_coaches['prev_coach'] = main_coaches['prev_coach'].fillna(main_coaches['coachID'])\n",
    "main_coaches['coach_change'] = main_coaches['coachID'] != main_coaches['prev_coach']\n",
    "\n",
    "# Create a \"spell ID\" that increments every time the coach changes\n",
    "main_coaches['coach_spell'] = main_coaches.groupby('tmID')['coach_change'].cumsum()\n",
    "\n",
    "# Count the cumulative years within each spell\n",
    "# We add 1 so the first year counts as 1 (or 0 if you prefer 'completed years')\n",
    "main_coaches['coach_tenure_years'] = main_coaches.groupby(['tmID', 'coach_spell']).cumcount() + 1\n",
    "\n",
    "print(main_coaches[['coachID', 'year', 'tmID', 'stint', 'coach_spell', 'coach_tenure_years', 'coach_change']][main_coaches['year'] == 11].sort_values(['year', 'tmID']))\n",
    "\n",
    "features.extend(['coach_tenure_years'])\n",
    "print(f\"Features: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Win Percentage for every season\n",
    "# Note: For the test year (Year 11), 'won' and 'lost' will be NaN or 0, which is fine\n",
    "# because we only use Lagged values for prediction.\n",
    "teams['win_pct'] = teams['won'] / (teams['won'] + teams['lost'])\n",
    "\n",
    "# 1. Previous Season Win Pct\n",
    "# Shift(1) grabs the value from Year t-1 and places it in the row for Year t\n",
    "teams['previous_season_win_pct'] = teams.groupby('tmID')['win_pct'].shift(1)\n",
    "\n",
    "# 2. Three Year Win Trend\n",
    "# We want the slope of win_pct for [t-3, t-2, t-1].\n",
    "# We apply a rolling window of 3 to the 'previous_season_win_pct' (which is already shifted).\n",
    "def calculate_trend(y):\n",
    "    # Only calculate if we have 3 data points\n",
    "    if len(y) < 3 or pd.isna(y).any():\n",
    "        return np.nan\n",
    "    # Fit linear regression to find slope\n",
    "    X = np.array([0, 1, 2]).reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y.values)\n",
    "    return model.coef_[0]\n",
    "\n",
    "teams['three_year_win_trend'] = teams.groupby('tmID')['previous_season_win_pct'] \\\n",
    "                                     .rolling(3) \\\n",
    "                                     .apply(calculate_trend) \\\n",
    "                                     .reset_index(0, drop=True)\n",
    "\n",
    "teams['previous_season_win_pct'] = teams['previous_season_win_pct'].fillna(teams['win_pct']).fillna(.4)\n",
    "teams['three_year_win_trend'] = teams['three_year_win_trend'].fillna(-0.02) # A negative trend is better\n",
    "\n",
    "display(teams[teams['year'] == 11][['year', 'tmID', 'previous_season_win_pct', 'three_year_win_trend']])\n",
    "\n",
    "features.extend(['previous_season_win_pct', 'three_year_win_trend'])\n",
    "print(f\"Features: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e2c5d",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering: Team Performance Metrics\n",
    "A coach's job security is heavily tied to team success. As described in the case, teams aim to achieve the greatest number of wins in the first part of the season.\n",
    "\n",
    "We engineer lag features to prevent data leakage (using $t-1$ data to predict $t$):\n",
    "* **`previous_season_win_pct`**: The win percentage ($\\frac{won}{won + lost}$) from the prior year.\n",
    "* **`three_year_win_trend`**: The slope of the win percentage over the last 3 years. A negative slope indicates a declining franchise, increasing the pressure to fire the coach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Playoff 'N' (No) to 1, 'Y' to 0\n",
    "# Handle NaN (Year 11) by treating it as 0 temporarily, but the shift handles the logic.\n",
    "teams = teams.sort_values(['tmID', 'year'])\n",
    "teams['missed_playoff'] = teams['playoff'].apply(lambda x: 1 if x == 'N' else 0)\n",
    "\n",
    "def get_streak(series):\n",
    "    # Shift to look at history only\n",
    "    history = series.shift(1).fillna(0)\n",
    "    streaks = []\n",
    "    current_streak = 0\n",
    "    for missed in history:\n",
    "        if missed == 1:\n",
    "            current_streak += 1\n",
    "        else:\n",
    "            current_streak = 0\n",
    "        streaks.append(current_streak)\n",
    "    return pd.Series(streaks, index=series.index)\n",
    "\n",
    "teams['playoff_miss_streak'] = teams.groupby('tmID', group_keys=False)['missed_playoff'].apply(get_streak)\n",
    "\n",
    "print(teams[teams['year'] == 11][['year', 'tmID', 'missed_playoff', 'playoff_miss_streak']])\n",
    "\n",
    "features.extend(['playoff_miss_streak'])\n",
    "print(f\"Features: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83a44a",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering: Playoff Droughts\n",
    "Qualifying for the playoffs is a primary measure of success. Repeated failures to qualify often lead to management changes.\n",
    "\n",
    "* **`playoff_miss_streak`**: The consecutive number of years a team has failed to reach the playoffs prior to the current season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate Efficiency for all player-years\n",
    "# Fill NaNs with 0 (important for test data where stats are empty)\n",
    "cols_to_fix = ['points', 'rebounds', 'assists', 'steals', 'blocks', \n",
    "               'fgAttempted', 'fgMade', 'ftAttempted', 'ftMade', 'turnovers']\n",
    "pt_stats = players_teams.copy()\n",
    "pt_stats[cols_to_fix] = pt_stats[cols_to_fix].fillna(0)\n",
    "\n",
    "pt_stats['efficiency'] = (pt_stats['points'] + pt_stats['rebounds'] + \n",
    "                          pt_stats['assists'] + pt_stats['steals'] + \n",
    "                          pt_stats['blocks'] - \n",
    "                          (pt_stats['fgAttempted'] - pt_stats['fgMade']) - \n",
    "                          (pt_stats['ftAttempted'] - pt_stats['ftMade']) - \n",
    "                          pt_stats['turnovers'])\n",
    "\n",
    "# 2. Prepare Lookup Table: Player Efficiency in Year Y\n",
    "eff_lookup = pt_stats[['playerID', 'year', 'efficiency']].copy()\n",
    "eff_lookup['next_year'] = eff_lookup['year'] + 1  # We join this to the NEXT year\n",
    "eff_lookup = eff_lookup[['playerID', 'next_year', 'efficiency']]\n",
    "\n",
    "# 3. Merge Current Roster (Year T) with Efficiency (from Year T-1)\n",
    "roster = players_teams[['playerID', 'year', 'tmID']]\n",
    "roster_with_talent = roster.merge(eff_lookup, \n",
    "                                  left_on=['playerID', 'year'], \n",
    "                                  right_on=['playerID', 'next_year'], \n",
    "                                  how='left')\n",
    "\n",
    "# 4. Aggregate by Team\n",
    "talent_score = roster_with_talent.groupby(['tmID', 'year'])['efficiency'].sum().reset_index()\n",
    "talent_score = talent_score.rename(columns={'efficiency': 'talent_score_aggregate'})\n",
    "\n",
    "# 5. Fill in missing talent scores for Year 1\n",
    "year_2_data = talent_score[talent_score['year'] == 2].set_index('tmID')['talent_score_aggregate']\n",
    "talent_score.loc[talent_score['year'] == 1, 'talent_score_aggregate'] = talent_score.loc[talent_score['year'] == 1, 'tmID'].map(year_2_data)\n",
    "\n",
    "display(talent_score[talent_score['year'] == 11])\n",
    "\n",
    "features.extend(['talent_score_aggregate'])\n",
    "print(f\"Features: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1315eca",
   "metadata": {},
   "source": [
    "### 6. Feature Engineering: Roster Talent (Aggregate Efficiency)\n",
    "A coach might be fired if they are underperforming relative to the talent available on the roster. We calculate player efficiency using the specific offensive and defensive statistics provided.\n",
    "\n",
    " The Efficiency metric is derived from standard stats found in `players_teams`:\n",
    "$$Efficiency = (PTS + REB + AST + STL + BLK) - (Missed FG + Missed FT + TO)$$\n",
    "\n",
    "We aggregate this for the **current** roster (Year $t$) using stats from Year $t-1$ to estimate the incoming \"talent level\" of the squad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Total Minutes played by each team in Year Y\n",
    "team_minutes = players_teams.groupby(['tmID', 'year'])['minutes'].sum().reset_index()\n",
    "team_minutes['next_year'] = team_minutes['year'] + 1 # Align to next year as denominator\n",
    "\n",
    "# 2. Minutes of RETURNING players (Players in Team T at Year Y who were also in Team T at Year Y-1)\n",
    "# We need their minutes from Y-1.\n",
    "prev_player_mins = players_teams[['playerID', 'year', 'tmID', 'minutes']].copy()\n",
    "prev_player_mins['next_year'] = prev_player_mins['year'] + 1\n",
    "prev_player_mins = prev_player_mins[['playerID', 'next_year', 'tmID', 'minutes']]\n",
    "# Join current roster with previous minutes on (Player, Team) match\n",
    "returning_players = roster.merge(prev_player_mins, \n",
    "                                 left_on=['playerID', 'year', 'tmID'], \n",
    "                                 right_on=['playerID', 'next_year', 'tmID'], \n",
    "                                 how='inner')\n",
    "\n",
    "returning_mins_sum = returning_players.groupby(['tmID', 'year'])['minutes'].sum().reset_index()\n",
    "returning_mins_sum.rename(columns={'minutes': 'retained_minutes'}, inplace=True)\n",
    "\n",
    "# 3. Calculate Index: Retained Minutes (from Y-1) / Total Minutes (from Y-1)\n",
    "continuity = returning_mins_sum.merge(team_minutes[['tmID', 'next_year', 'minutes']], \n",
    "                                      left_on=['tmID', 'year'], \n",
    "                                      right_on=['tmID', 'next_year'], \n",
    "                                      how='left')\n",
    "\n",
    "continuity['roster_continuity_index'] = continuity['retained_minutes'] / continuity['minutes']\n",
    "continuity['roster_continuity_index'] = continuity['roster_continuity_index'].fillna(0)\n",
    "continuity = continuity[['tmID', 'year', 'roster_continuity_index']]\n",
    "\n",
    "display(continuity[continuity['year'] == 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294be9a2",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering: Roster Continuity\n",
    "This metric determines how much of the team remains the same from the previous year. High turnover in players might excuse a coach's poor performance, while high continuity suggests the coach is the only variable left to change.\n",
    "\n",
    "* **`roster_continuity_index`**: The proportion of total minutes played in Year $t$ by players who were also on the team in Year $t-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37dfd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by year to calculate cumulative sum correctly\n",
    "all_coaches = coaches.copy().sort_values('year')\n",
    "\n",
    "# Sum wins/losses per coach per year (in case of multiple stints)\n",
    "coach_annual = all_coaches.groupby(['coachID', 'year'])[['won', 'lost']].sum().reset_index()\n",
    "\n",
    "# Calculate expanding sum (cumulative history) shifted by 1 (exclude current year)\n",
    "coach_annual['cum_won'] = coach_annual.groupby('coachID')['won'] \\\n",
    "                                      .transform(lambda x: x.shift(1).expanding().sum())\n",
    "coach_annual['cum_lost'] = coach_annual.groupby('coachID')['lost'] \\\n",
    "                                       .transform(lambda x: x.shift(1).expanding().sum())\n",
    "\n",
    "# Calculate lifetime win percentage\n",
    "coach_annual['coach_lifetime_win_pct'] = (coach_annual['cum_won'] / (coach_annual['cum_won'] + coach_annual['cum_lost'])).fillna(.4) # Fill missing values with .4\n",
    "coach_annual = coach_annual[['coachID', 'year', 'coach_lifetime_win_pct']]\n",
    "\n",
    "display(coach_annual[coach_annual['year'] == 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee83b3b",
   "metadata": {},
   "source": [
    "### 8. Feature Engineering: Coach Lifetime Win Percentage\n",
    "Historical performance across all teams managed by a specific coach. A \"legendary\" coach with a high lifetime win percentage typically has more job security than a novice.\n",
    "\n",
    "* **`coach_lifetime_win_pct`**: Expanding mean of wins divided by total games for a `coachID` across their entire career up to Year $t-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with main coaches (Year, Team, Coach)\n",
    "final_df = main_coaches[['year', 'tmID', 'coachID', 'coach_tenure_years']]\n",
    "\n",
    "# Merge Coach Lifetime Stats\n",
    "final_df = final_df.merge(coach_annual[['coachID', 'year', 'coach_lifetime_win_pct']], \n",
    "                          on=['coachID', 'year'], how='left')\n",
    "\n",
    "# Merge Team Stats (Win trends, Playoff streaks)\n",
    "final_df = final_df.merge(teams[['year', 'tmID', 'previous_season_win_pct', \n",
    "                                 'three_year_win_trend', 'playoff_miss_streak']], \n",
    "                          on=['year', 'tmID'], how='left')\n",
    "\n",
    "# Merge Roster Stats (Talent, Continuity)\n",
    "final_df = final_df.merge(talent_score, on=['year', 'tmID'], how='left')\n",
    "final_df = final_df.merge(continuity[['year', 'tmID', 'roster_continuity_index']], \n",
    "                          on=['year', 'tmID'], how='left')\n",
    "final_df['roster_continuity_index'] = final_df['roster_continuity_index'].fillna(.5)\n",
    "\n",
    "final_df = final_df.merge(target_df[['year', 'tmID', 'CoachChange']], \n",
    "                          on=['year', 'tmID'], how='left')\n",
    "\n",
    "final_df = final_df.sort_values(by=['year', 'tmID']).reset_index(drop=True)\n",
    "\n",
    "print(final_df.head())\n",
    "\n",
    "X = final_df.drop(['year', 'tmID', 'coachID', 'CoachChange'], axis=1)\n",
    "y = final_df['CoachChange']\n",
    "\n",
    "print()\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "display(X.head())\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55243c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- C. Check Correlation ---\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='Blues', fmt='.1f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# You can also manually find high-correlation pairs\n",
    "# Select upper triangle of correlation matrix\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.9\n",
    "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "if high_corr_features:\n",
    "    print(f\"\\nWARNING!: High Correlation remaining in features: {high_corr_features}\")\n",
    "    print(\"Consider dropping one feature from each correlated pair.\")\n",
    "else:\n",
    "    print(\"\\nNo highly correlated (r > 0.9) features found. Ready for modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e14661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer, classification_report, matthews_corrcoef\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb76da",
   "metadata": {},
   "source": [
    "### 9. Evaluation Strategy: Yearly Walk-Forward Validation\n",
    "Because this is time-series data (Years 1 through 10), standard K-Fold cross-validation would introduce look-ahead bias (using future data to predict the past).\n",
    "\n",
    "Instead, we use **Walk-Forward Validation**:\n",
    "1.  **Train**: Years $1$ to $t-1$\n",
    "2.  **Test**: Year $t$\n",
    "3.  **Repeat**: Increment $t$ from Year 3 to Year 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearlyWalkForwardSplit:\n",
    "    \"\"\"\n",
    "    Perform walk-forward validation based on an external year series (list/array/column).\n",
    "    \n",
    "    Train: All years prior to the current test year.\n",
    "    Test:  The specific current test year.\n",
    "    \"\"\"\n",
    "    def __init__(self, year_series):\n",
    "        self.year_series = np.array(year_series)\n",
    "        self.unique_years = np.sort(np.unique(self.year_series))\n",
    "        \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(self.unique_years) - 2\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        if len(X) != len(self.year_series):\n",
    "            raise ValueError(f\"Data length mismatch! X has {len(X)} rows, but year_series has {len(self.year_series)}.\")\n",
    "\n",
    "        for i in range(2, len(self.unique_years)):\n",
    "            test_year = self.unique_years[i]\n",
    "            \n",
    "            # Train on everything strictly BEFORE the test year\n",
    "            train_mask = self.year_series < test_year\n",
    "            \n",
    "            # Test on ONLY the current test year\n",
    "            test_mask = self.year_series == test_year\n",
    "            \n",
    "            train_indices = np.flatnonzero(train_mask)\n",
    "            test_indices = np.flatnonzero(test_mask)\n",
    "            \n",
    "            yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19deb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_year = 10\n",
    "\n",
    "X_train = X[final_df['year'] < test_year]\n",
    "y_train = y[final_df['year'] < test_year]\n",
    "\n",
    "X_test = X[final_df['year'] == test_year]\n",
    "y_test = y[final_df['year'] == test_year]\n",
    "\n",
    "walk_forward_cv = YearlyWalkForwardSplit(final_df[final_df['year'] < test_year]['year'])\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1, zero_division=0)\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42)\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "lr_params = {\n",
    "    'lr__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator=lr_pipeline,\n",
    "    param_grid=lr_params,\n",
    "    scoring=mcc_scorer,\n",
    "    cv=walk_forward_cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "# 5. Get Results\n",
    "print(f\"Best Hyperparameters: {lr_grid.best_params_}\")\n",
    "print(f\"Best Cross-Validated MCC Score: {lr_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03883ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "rf_params = {\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'rf__max_features': ['sqrt', 'log2'],\n",
    "    'rf__max_depth': [10, 20, None],\n",
    "    'rf__min_samples_split': [2, 5],\n",
    "    'rf__min_samples_leaf': [1, 2],\n",
    "    'rf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=rf_params,\n",
    "    scoring=mcc_scorer,\n",
    "    cv=walk_forward_cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# 5. Get Results\n",
    "print(f\"Best Hyperparameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best Cross-Validated MCC Score: {rf_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab55d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_params = {\n",
    "  'n_estimators' : [100, 200, 500],\n",
    "  'learning_rate' : [0.01, 0.05, 0.1],\n",
    "  'max_depth' : [3, 4, 5, 6],\n",
    "  'subsample' : [0.6, 0.8, 1.0],\n",
    "  'scale_pos_weight' : [1, 10, 25],\n",
    "}\n",
    "\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb_classifier,\n",
    "    param_grid=xgb_params,\n",
    "    scoring=mcc_scorer,\n",
    "    cv=walk_forward_cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(\n",
    "  X_train,\n",
    "  y_train\n",
    ")\n",
    "\n",
    "print(f\"Best Hyperparameters: {xgb_grid.best_params_}\")\n",
    "print(f\"Best Cross-Validated MCC Score: {xgb_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVMs strictly require feature scaling (StandardScaler) to converge correctly.\n",
    "svc_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(random_state=42, probability=True)) \n",
    "])\n",
    "\n",
    "# C: Controls strictness. Lower C = softer margins (prevents overfitting).\n",
    "# kernel: 'rbf' is standard for non-linear complex boundaries.\n",
    "# class_weight: Crucial for imbalanced coach firing data.\n",
    "svc_params = {\n",
    "    'svc__C': [0.1, 1, 10, 50],\n",
    "    'svc__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'svc__class_weight': ['balanced', {0:1, 1:5}, {0:1, 1:10}]\n",
    "}\n",
    "\n",
    "# 4. Setup Grid Search\n",
    "svc_grid = GridSearchCV(\n",
    "    estimator=svc_pipeline,\n",
    "    param_grid=svc_params,\n",
    "    scoring=mcc_scorer,\n",
    "    cv=walk_forward_cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "svc_grid.fit(\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "print(f\"Best Hyperparameters: {svc_grid.best_params_}\")\n",
    "print(f\"Best Cross-Validated MCC Score: {svc_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a590679",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "mlp_params = {\n",
    "  'mlp__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "  'mlp__activation': ['relu', 'tanh'],\n",
    "  'mlp__alpha': [0.0001, 0.001],\n",
    "  'mlp__learning_rate_init': [0.001, 0.01],\n",
    "  'mlp__max_iter': [2000],\n",
    "}\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "  ('scaler', StandardScaler()),\n",
    "  ('mlp', MLPClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "mlp_grid = GridSearchCV(\n",
    "  mlp_pipeline, \n",
    "  mlp_params,\n",
    "  cv=walk_forward_cv, \n",
    "  scoring=mcc_scorer, \n",
    "  verbose=1,\n",
    "  n_jobs=-1,\n",
    ")\n",
    "\n",
    "mlp_grid.fit(\n",
    "  X_train, \n",
    "  y_train,\n",
    "  mlp__sample_weight=sample_weights\n",
    ")\n",
    "\n",
    "print(f\"Best Hyperparameters: {mlp_grid.best_params_}\")\n",
    "print(f\"Best Cross-Validated MCC Score: {mlp_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303dc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, auc, matthews_corrcoef\n",
    "\n",
    "best_estimators = {'Logistic Regression': lr_grid.best_estimator_, 'Random Forest': rf_grid.best_estimator_, 'XGBClassifier': xgb_grid.best_estimator_, 'SVC': svc_grid.best_estimator_, 'MLP': mlp_grid.best_estimator_}\n",
    "\n",
    "def get_metrics_dict(y_true, y_pred, model_name, y_proba=None):\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "    }\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            metrics['ROC AUC'] = roc_auc_score(y_true, y_proba)\n",
    "        except ValueError:\n",
    "            metrics['ROC AUC'] = None\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "        metrics['PR AUC'] = auc(recall, precision)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for name, estimator in best_estimators.items():\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    y_proba = None\n",
    "    if hasattr(estimator, 'predict_proba'):\n",
    "        y_proba = estimator.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics = get_metrics_dict(y_test, y_pred, name, y_proba)\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df = metrics_df.sort_values(by=['MCC', 'PR AUC', 'ROC AUC'], ascending=[False, False, False])\n",
    "\n",
    "metrics_0_to_1 = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC', 'PR AUC']\n",
    "metrics_mcc = ['MCC']\n",
    "\n",
    "styled_metrics_df = metrics_df.style\\\n",
    "    .background_gradient(cmap='RdYlGn', subset=metrics_0_to_1, vmin=0, vmax=1)\\\n",
    "    .background_gradient(cmap='RdYlGn', subset=metrics_mcc, vmin=-1, vmax=1)\\\n",
    "    .format(precision=4)\n",
    "\n",
    "display(styled_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59963ea",
   "metadata": {},
   "source": [
    "### 10. Final Prediction for Test Season (Year 11)\n",
    "Using the best-performing models from our cross-validation, we now retrain on the entire historical dataset (Years 1-10) and generate probabilities for Year 11.\n",
    "\n",
    "This output satisfies the project requirement to identify the \"Set of teams that will change coaches\" for the test season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_train = X[final_df['year'] < 11]\n",
    "y_final_train = y[final_df['year'] < 11]\n",
    "\n",
    "X_final_test = X[final_df['year'] == 11]\n",
    "results = {}\n",
    "\n",
    "print(\"Final season (Season 11) mid-season coach change predictions: \\n\")\n",
    "\n",
    "for name in metrics_df['Model'].values:\n",
    "    estimator = best_estimators[name]\n",
    "\n",
    "    # Refit using Year 10 data\n",
    "    estimator.fit(X_final_train, y_final_train)\n",
    "    y_pred = estimator.predict(X_final_test)\n",
    "    y_proba = estimator.predict_proba(X_final_test)\n",
    "    \n",
    "    final_test_season = final_df[final_df['year'] == 11].copy()\n",
    "    final_test_season['CoachChange'] = y_pred\n",
    "    final_test_season['CoachChange_proba'] = y_proba[:, 1]\n",
    "    final_test_season = final_test_season.sort_values(by='CoachChange_proba', ascending=False)\n",
    "    results[name] = final_test_season[['tmID', 'coachID', 'CoachChange', 'CoachChange_proba']][final_test_season['CoachChange'] == True]\n",
    "\n",
    "for name, result in results.items():\n",
    "  print(f\"{name}: {len(result)}\")\n",
    "  print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
