{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07595fa",
   "metadata": {},
   "source": [
    "# MVP Award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93c21fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "awards_data = pd.read_csv(\"../../initial_data/awards_players.csv\")\n",
    "teams_data = pd.read_csv(\"../../initial_data/teams.csv\")\n",
    "players_teams_clean = pd.read_csv(\"../awards_data/players_teams_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e27ec45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams data columns:\n",
      "['year', 'lgID', 'tmID', 'franchID', 'confID', 'divID', 'rank', 'playoff', 'seeded', 'firstRound', 'semis', 'finals', 'name', 'o_fgm', 'o_fga', 'o_ftm', 'o_fta', 'o_3pm', 'o_3pa', 'o_oreb', 'o_dreb', 'o_reb', 'o_asts', 'o_pf', 'o_stl', 'o_to', 'o_blk', 'o_pts', 'd_fgm', 'd_fga', 'd_ftm', 'd_fta', 'd_3pm', 'd_3pa', 'd_oreb', 'd_dreb', 'd_reb', 'd_asts', 'd_pf', 'd_stl', 'd_to', 'd_blk', 'd_pts', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB', 'won', 'lost', 'GP', 'homeW', 'homeL', 'awayW', 'awayL', 'confW', 'confL', 'min', 'attend', 'arena']\n",
      "\n",
      "Players teams clean columns:\n",
      "['playerID', 'year', 'team', 'minutes', 'games_played', 'total_points', 'total_rebounds', 'total_assists', 'points_per_min', 'assists_per_min', 'rebounds_per_min', 'steals_per_min', 'blocks_per_min', 'turnovers_per_min', 'FG%', 'FT%', 'Three%', 'Three Rate']\n",
      "\n",
      "Teams data sample:\n",
      "   year  lgID tmID franchID confID  divID  rank playoff  seeded firstRound  \\\n",
      "0     9  WNBA  ATL      ATL     EA    NaN     7       N       0        NaN   \n",
      "1    10  WNBA  ATL      ATL     EA    NaN     2       Y       0          L   \n",
      "2     1  WNBA  CHA      CHA     EA    NaN     8       N       0        NaN   \n",
      "3     2  WNBA  CHA      CHA     EA    NaN     4       Y       0          W   \n",
      "4     3  WNBA  CHA      CHA     EA    NaN     2       Y       0          L   \n",
      "\n",
      "   ...  GP homeW homeL  awayW  awayL  confW  confL   min  attend  \\\n",
      "0  ...  34     1    16      3     14      2     18  6825  141379   \n",
      "1  ...  34    12     5      6     11     10     12  6950  120737   \n",
      "2  ...  32     5    11      3     13      5     16  6475   90963   \n",
      "3  ...  32    11     5      7      9     15      6  6500  105525   \n",
      "4  ...  32    11     5      7      9     12      9  6450  106670   \n",
      "\n",
      "                arena  \n",
      "0       Philips Arena  \n",
      "1       Philips Arena  \n",
      "2  Charlotte Coliseum  \n",
      "3  Charlotte Coliseum  \n",
      "4  Charlotte Coliseum  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the column names in teams_data\n",
    "print(\"Teams data columns:\")\n",
    "print(teams_data.columns.tolist())\n",
    "print(\"\\nPlayers teams clean columns:\")\n",
    "print(players_teams_clean.columns.tolist())\n",
    "print(\"\\nTeams data sample:\")\n",
    "print(teams_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306ca54",
   "metadata": {},
   "source": [
    "## Create MVP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e4d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVP data shape: (1876, 23)\n",
      "\n",
      "Columns: ['playerID', 'year', 'team', 'minutes', 'games_played', 'total_points', 'total_rebounds', 'total_assists', 'points_per_min', 'assists_per_min', 'rebounds_per_min', 'steals_per_min', 'blocks_per_min', 'turnovers_per_min', 'FG%', 'FT%', 'Three%', 'Three Rate', 'team_wins', 'team_losses', 'conference_rank', 'playoff_made', 'confID']\n",
      "\n",
      "Sample data:\n",
      "     playerID  year team  minutes  games_played  total_points  total_rebounds  \\\n",
      "0  abrossv01w     2  MIN      846            26           343             174   \n",
      "1  abrossv01w     3  MIN      805            27           314             146   \n",
      "2  abrossv01w     4  MIN      792            30           318             141   \n",
      "3  abrossv01w     5  MIN      462            22           146              74   \n",
      "4  abrossv01w     6  MIN      777            31           304             107   \n",
      "\n",
      "   total_assists  points_per_min  assists_per_min  ...  turnovers_per_min  \\\n",
      "0             53        0.405437         0.062648  ...           0.100473   \n",
      "1             60        0.390062         0.074534  ...           0.114286   \n",
      "2             82        0.401515         0.103535  ...           0.113636   \n",
      "3             45        0.316017         0.097403  ...           0.093074   \n",
      "4             60        0.391248         0.077220  ...           0.102960   \n",
      "\n",
      "        FG%       FT%    Three%  Three Rate  team_wins  team_losses  \\\n",
      "0  0.389078  0.727273  0.250000    0.259386         12           20   \n",
      "1  0.376582  0.482759  0.333333    0.189873         10           22   \n",
      "2  0.392982  0.704082  0.304878    0.287719         18           16   \n",
      "3  0.352518  0.608696  0.377358    0.381295         18           16   \n",
      "4  0.394928  0.726027  0.402439    0.297101         14           20   \n",
      "\n",
      "   conference_rank  playoff_made  confID  \n",
      "0                6             0       1  \n",
      "1                8             0       1  \n",
      "2                4             1       1  \n",
      "3                3             1       1  \n",
      "4                6             0       1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "âœ… Saved to mvp_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Join dataset players_teams_clean data with teams_data (team_wins, team_losses, rank, playoff_made)\n",
    "# Note: players_teams_clean has 'team' column, teams_data has 'tmID' column\n",
    "mvp_data = players_teams_clean.merge(\n",
    "    teams_data[['year', 'tmID', 'won', 'lost', 'rank', 'playoff', 'confID']], \n",
    "    left_on=['year', 'team'], \n",
    "    right_on=['year', 'tmID'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "mvp_data.rename(columns={\n",
    "    'won': 'team_wins', \n",
    "    'lost': 'team_losses', \n",
    "    'rank': 'conference_rank', \n",
    "    'playoff': 'playoff_made'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop the duplicate tmID column (we already have 'team')\n",
    "mvp_data.drop(columns=['tmID'], inplace=True)\n",
    "\n",
    "# Change Playoff from N / Y to 0 / 1\n",
    "mvp_data['playoff_made'] = mvp_data['playoff_made'].map({'Y': 1, 'N': 0})\n",
    "# Change ConfID to numeric  EA / WE to 0 / 1\n",
    "mvp_data['confID'] = mvp_data['confID'].astype('category').cat.codes\n",
    "\n",
    "print(f\"MVP data shape: {mvp_data.shape}\")\n",
    "print(f\"\\nColumns: {mvp_data.columns.tolist()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(mvp_data.head())\n",
    "\n",
    "# Save csv (relative path from current location)\n",
    "mvp_data.to_csv(\"mvp_data.csv\", index=False)\n",
    "print(f\"\\nâœ… Saved to mvp_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486be5fc",
   "metadata": {},
   "source": [
    "## Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac64e0b",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73950d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MVP candidates: 310\n",
      "MVP winners in dataset: 10\n",
      "Years available: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "Class distribution:\n",
      "MVP_winner\n",
      "0    300\n",
      "1     10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "      playerID  year  team_wins  conference_rank  MVP_winner\n",
      "32  andrame01w     2         22                1           0\n",
      "37  arcaija01w     1         27                2           0\n",
      "38  arcaija01w     2         19                4           0\n",
      "39  arcaija01w     3         24                2           0\n",
      "40  arcaija01w     4         20                2           0\n",
      "41  arcaija01w     6         19                3           0\n",
      "59   azzije01w     2         19                3           0\n",
      "60   azzije01w     3         20                3           0\n",
      "74  baranel01w     2         20                3           0\n",
      "76  baranel01w     5         18                2           0\n"
     ]
    }
   ],
   "source": [
    "# Prepare MVP prediction dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load data\n",
    "mvp_data = pd.read_csv(\"mvp_data.csv\")\n",
    "awards_data = pd.read_csv(\"../../initial_data/awards_players.csv\")\n",
    "\n",
    "# Step 1: Filter to realistic MVP candidates\n",
    "# Only players with significant playing time and on winning teams\n",
    "mvp_candidates = mvp_data[\n",
    "    (mvp_data['minutes'] >= 800) &  # Significant playing time\n",
    "    (mvp_data['games_played'] >= 25) &  # Played most of season\n",
    "    (mvp_data['team_wins'] / (mvp_data['team_wins'] + mvp_data['team_losses']) >= 0.500)  # Winning team\n",
    "].copy()\n",
    "\n",
    "# Step 2: Add MVP winner target variable\n",
    "mvp_winners = awards_data[awards_data['award'] == 'Most Valuable Player'][['year', 'playerID']]\n",
    "mvp_candidates['MVP_winner'] = mvp_candidates.apply(\n",
    "    lambda row: 1 if ((mvp_winners['year'] == row['year']) & \n",
    "                      (mvp_winners['playerID'] == row['playerID'])).any() else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Total MVP candidates: {len(mvp_candidates)}\")\n",
    "print(f\"MVP winners in dataset: {mvp_candidates['MVP_winner'].sum()}\")\n",
    "print(f\"Years available: {sorted(mvp_candidates['year'].unique())}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(mvp_candidates['MVP_winner'].value_counts())\n",
    "print(f\"\\nSample data:\")\n",
    "print(mvp_candidates[['playerID', 'year', 'team_wins', 'conference_rank', 'MVP_winner']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f486efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for MVP prediction:\n",
      "1. playerID\n",
      "2. year\n",
      "3. team\n",
      "4. minutes\n",
      "5. games_played\n",
      "6. total_points\n",
      "7. total_rebounds\n",
      "8. total_assists\n",
      "9. points_per_min\n",
      "10. assists_per_min\n",
      "11. rebounds_per_min\n",
      "12. steals_per_min\n",
      "13. blocks_per_min\n",
      "14. turnovers_per_min\n",
      "15. FG%\n",
      "16. FT%\n",
      "17. Three%\n",
      "18. Three Rate\n",
      "19. team_wins\n",
      "20. team_losses\n",
      "21. conference_rank\n",
      "22. playoff_made\n",
      "23. confID\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns for the model\n",
    "feature_columns = [\n",
    "    'playerID', 'year', 'team','minutes','games_played','total_points','total_rebounds','total_assists','points_per_min','assists_per_min',\n",
    "    'rebounds_per_min','steals_per_min','blocks_per_min','turnovers_per_min','FG%','FT%','Three%','Three Rate','team_wins','team_losses',\n",
    "    'conference_rank','playoff_made','confID']\n",
    "\n",
    "print(\"Features for MVP prediction:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afda3a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available years: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "ğŸ“š Training years: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "ğŸ§ª Test years: [9, 10]\n",
      "\n",
      "ğŸ“Š Dataset Split:\n",
      "Training set: 255 candidates, 8 MVP winners\n",
      "Test set: 55 candidates, 2 MVP winners\n"
     ]
    }
   ],
   "source": [
    "# MVP Prediction Pipeline - Configure Training and Test Years\n",
    "\n",
    "# Available years\n",
    "available_years = sorted(mvp_candidates['year'].unique())\n",
    "print(f\"Available years: {available_years}\")\n",
    "\n",
    "# Configure training and test years\n",
    "# Modify these lists based on your needs\n",
    "train_years = [1, 2, 3, 4, 5, 6, 7, 8]  # Years to train the model\n",
    "test_years = [9, 10]  # Years to test the model\n",
    "\n",
    "print(f\"\\nğŸ“š Training years: {train_years}\")\n",
    "print(f\"ğŸ§ª Test years: {test_years}\")\n",
    "\n",
    "# Verify years exist in dataset\n",
    "missing_train = [y for y in train_years if y not in available_years]\n",
    "missing_test = [y for y in test_years if y not in available_years]\n",
    "\n",
    "if missing_train:\n",
    "    print(f\"âš ï¸  Warning: Training years {missing_train} not found in dataset\")\n",
    "if missing_test:\n",
    "    print(f\"âš ï¸  Warning: Test years {missing_test} not found in dataset\")\n",
    "    \n",
    "# Prepare train/test splits\n",
    "X_train = mvp_candidates[mvp_candidates['year'].isin(train_years)][feature_columns]\n",
    "y_train = mvp_candidates[mvp_candidates['year'].isin(train_years)]['MVP_winner']\n",
    "X_test = mvp_candidates[mvp_candidates['year'].isin(test_years)][feature_columns]\n",
    "y_test = mvp_candidates[mvp_candidates['year'].isin(test_years)]['MVP_winner']\n",
    "\n",
    "# Keep full records for detailed analysis\n",
    "train_data = mvp_candidates[mvp_candidates['year'].isin(train_years)].copy()\n",
    "test_data = mvp_candidates[mvp_candidates['year'].isin(test_years)].copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset Split:\")\n",
    "print(f\"Training set: {len(X_train)} candidates, {y_train.sum()} MVP winners\")\n",
    "print(f\"Test set: {len(X_test)} candidates, {y_test.sum()} MVP winners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88df8685",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'andrame01w'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29996\\4133257534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Scale features (important for logistic regression)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_train_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 )\n\u001b[0;32m   1388\u001b[0m             ):\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \"\"\"\n\u001b[0;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         X = validate_data(\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2944\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2945\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'andrame01w'"
     ]
    }
   ],
   "source": [
    "# Train the MVP Prediction Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Scale features (important for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model with balanced class weights\n",
    "# This handles the imbalanced dataset (few MVP winners vs many candidates)\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]  # Probability of being MVP\n",
    "\n",
    "# Store predictions in test data\n",
    "test_data['mvp_probability'] = y_pred_proba\n",
    "test_data['mvp_prediction'] = y_pred\n",
    "\n",
    "print(\"âœ… Model training complete!\")\n",
    "print(f\"Training accuracy: {model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"Test accuracy: {model.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nğŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not MVP', 'MVP']))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nğŸ” Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"True Negatives: {cm[0, 0]} | False Positives: {cm[0, 1]}\")\n",
    "print(f\"False Negatives: {cm[1, 0]} | True Positives: {cm[1, 1]}\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nâ­ Top 10 Most Important Features:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': model.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nPositive impact (increases MVP probability):\")\n",
    "print(feature_importance.head(5).to_string(index=False))\n",
    "print(\"\\nNegative impact (decreases MVP probability):\")\n",
    "print(feature_importance.tail(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7076570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Year MVP Predictions with Rankings\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MVP PREDICTIONS BY YEAR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for year in sorted(test_data['year'].unique()):\n",
    "    year_data = test_data[test_data['year'] == year].copy()\n",
    "    year_data = year_data.sort_values('mvp_probability', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ€ Year {year} - Top 10 MVP Candidates\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get actual MVP if exists\n",
    "    actual_mvp = year_data[year_data['MVP_winner'] == 1]\n",
    "    if len(actual_mvp) > 0:\n",
    "        actual_mvp_name = actual_mvp.iloc[0]['playerID']\n",
    "        print(f\"ğŸ† Actual MVP: {actual_mvp_name}\")\n",
    "    else:\n",
    "        print(\"ğŸ† Actual MVP: Data not available\")\n",
    "    \n",
    "    # Show top 10 predictions\n",
    "    top_10 = year_data.head(10)\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6}{'Player':<25}{'Team':<6}{'MVP Prob':<12}{'Predicted':<12}{'PPG':<8}{'Wins':<6}\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "        is_mvp = \"âœ… MVP\" if row['MVP_winner'] == 1 else \"\"\n",
    "        predicted = \"ğŸ¯ PRED\" if row['mvp_prediction'] == 1 else \"\"\n",
    "        \n",
    "        print(f\"{idx:<6}{row['playerID']:<25}{row['team']:<6}\"\n",
    "              f\"{row['mvp_probability']:.4f}{'':6}{predicted:<12}\"\n",
    "              f\"{row['points_per_game']:.1f}{'':6}{int(row['team_wins']):<6}{is_mvp}\")\n",
    "    \n",
    "    # Prediction summary\n",
    "    predicted_mvp = year_data[year_data['mvp_prediction'] == 1]\n",
    "    if len(predicted_mvp) > 0:\n",
    "        pred_name = predicted_mvp.iloc[0]['playerID']\n",
    "        pred_prob = predicted_mvp.iloc[0]['mvp_probability']\n",
    "        print(f\"\\nğŸ¯ Model's MVP Pick: {pred_name} (probability: {pred_prob:.4f})\")\n",
    "    else:\n",
    "        top_candidate = year_data.iloc[0]\n",
    "        print(f\"\\nğŸ¯ Model's Top Candidate: {top_candidate['playerID']} \"\n",
    "              f\"(probability: {top_candidate['mvp_probability']:.4f})\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Analysis Complete!\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvACFinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
